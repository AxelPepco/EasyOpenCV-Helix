package org.firstinspires.ftc.teamcode.drive.opmode;
import org.firstinspires.ftc.robotcore.external.hardware.camera.WebcamName;
import com.acmerobotics.dashboard.config.Config;
import com.acmerobotics.dashboard.telemetry.TelemetryPacket;
import com.qualcomm.robotcore.eventloop.opmode.Autonomous;
import com.qualcomm.robotcore.eventloop.opmode.LinearOpMode;

import org.opencv.core.Core;
import org.opencv.core.Mat;
import org.opencv.core.Point;
import org.opencv.core.Rect;
import org.opencv.core.Scalar;
import org.opencv.imgproc.Imgproc;
import org.openftc.easyopencv.OpenCvCamera;
import org.openftc.easyopencv.OpenCvCameraFactory;
import org.openftc.easyopencv.OpenCvCameraRotation;
import org.openftc.easyopencv.OpenCvInternalCamera;
import org.openftc.easyopencv.OpenCvPipeline;


@Config
@Autonomous

public class colorperc extends LinearOpMode {


public int caz = 0;
int cameraMonitorViewId;
OpenCvCamera camera;

    //WebcamName webcamName = hardwareMap.get(WebcamName.class, "Webcam 1");



    @Override
    public  void runOpMode() throws InterruptedException {
        TelemetryPacket packet = new TelemetryPacket();

        cameraMonitorViewId = hardwareMap.appContext.getResources().getIdentifier("cameraMonitorViewId", "id", hardwareMap.appContext.getPackageName());
        //camera =  OpenCvCameraFactory.getInstance().createInternalCamera(OpenCvInternalCamera.CameraDirection.BACK, cameraMonitorViewId);
        WebcamName webcamName = hardwareMap.get(WebcamName.class, "Webcam 1");

        camera = OpenCvCameraFactory.getInstance().createWebcam(webcamName, cameraMonitorViewId);
        camera.openCameraDeviceAsync(new OpenCvCamera.AsyncCameraOpenListener() {
            @Override
            public void onOpened() {

                camera.setPipeline(new colorperc.EmptyPipeline());
                camera.startStreaming(640, 480, OpenCvCameraRotation.UPRIGHT);


            }

            @Override
            public void onError(int errorCode) {
                /*
                 * This will be called if the camera could not be opened
                 */
            }
        });
        while(opModeInInit()){

//            if(caz == 1){
//                telemetry.addData("Caz: ","Stanga");
//            }else if(caz == 2){
//                telemetry.addData("Caz: ","Centru");
//            }else if(caz == 3){
//                telemetry.addData("Caz: ","Dreapta");
//            }
        telemetry.update();
        }
        waitForStart();

    }


    class EmptyPipeline extends OpenCvPipeline {
        public double hueMin = 0;
        public double hueMax = 180;
        public double saturationMin = 50;
        public double saturationMax = 255;
        public double valueMin = 20;
        public double valueMax = 255;
        int x1 = 70, y1 = 180, w1 = 130, h1 = 90;
        int x2 = 350, y2 = 160, w2 = 130, h2 = 90;
        int minim = 100;

        @Override
        public Mat processFrame(Mat input) {
            Mat frame_hsv = new Mat();
            Mat mask = new Mat();
            Imgproc.cvtColor(input, frame_hsv, Imgproc.COLOR_RGB2HSV);


            Scalar lowerBound = new Scalar(hueMin, saturationMin, valueMin);
            Scalar upperBound = new Scalar(hueMax, saturationMax, valueMax);

            Core.inRange(frame_hsv, lowerBound, upperBound, mask);

            Mat reg1 = mask.submat(new Rect(x1, y1, w1, h1));
            Mat reg2 = mask.submat(new Rect(x2, y2, w2, h2));



            int pixels1 = Core.countNonZero(reg1);
            int pixels2 = Core.countNonZero(reg2);
            telemetry.addData("bau", String.valueOf(pixels1));
            telemetry.addData("hau", String.valueOf(pixels2));

            if (pixels1 > minim || pixels2 > minim) {
                if (pixels1 > pixels2) {
                    caz = 1;
                } else {
                    caz = 2;
                }
            } else {
                caz = 3;
            }

            telemetry.addData("e: ", caz);
            telemetry.update();
            Imgproc.cvtColor(mask,mask,Imgproc.COLOR_GRAY2RGB);
            Imgproc.rectangle(mask, new Point(x1, y1), new Point(x1 + w1, y1 + h1), new Scalar(0, 255, 0), 2);
            Imgproc.rectangle(mask, new Point(x2, y2), new Point(x2 + w2, y2 + h2), new Scalar(0, 255, 0), 2);

            frame_hsv.release();
            reg1.release();
            reg2.release();
            return mask;
        }

        int countPixels(Mat image){
            if (image.empty()) {

                return 0;
            }
            int ans = 0, n = image.cols(), m = image.rows();
            for(int i = 0; i < n; i++){
                for(int j = 0; j < m; j++){
//                    double[] data = new double[3]; // Adjust size according to the number of channels
//                    image.get(i, j, data);
//                    telemetry.addData("asa", data.toString());
                    int channels = image.channels();
                    telemetry.addData("jfj",String.valueOf(channels));
                }
            }
            return ans;
        }

    }
}
